{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpmnJT_Gwlnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dset\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxY5Wbkz8X3w",
        "colab_type": "code",
        "outputId": "041f93f5-5d48-4ac9-c8f8-b7213b0aef7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "print(\"--sys.version--\")\n",
        "print(sys.version)\n",
        "\n",
        "print(\"\\n--torch.__version__--\")\n",
        "print(torch.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--sys.version--\n",
            "3.6.8 (default, Jan 14 2019, 11:02:34) \n",
            "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n",
            "\n",
            "--torch.__version__--\n",
            "1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaQS7qKrxY2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 20\n",
        "total_epoch = 100\n",
        "learning_rate = 0.01\n",
        "use_cuda = torch.cuda.is_available()\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-ZHjq8QUDWH",
        "colab_type": "code",
        "outputId": "8005340d-da5b-41d8-cbe7-3da8dd3e6cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZgjzet_Blsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dset.ImageFolder(root=\"/content/gdrive/My Drive/Colab Notebooks/pytorch/gender classification/train\", transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "test_dataset = dset.ImageFolder(root=\"/content/gdrive/My Drive/Colab Notebooks/pytorch/gender classification/test\", transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emsGTTIEDsb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader):\n",
        "  model.train()\n",
        "  \n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "  losses = []\n",
        "  for i, (image, label) in enumerate(train_loader):\n",
        "    \n",
        "    if use_cuda:\n",
        "      image = image.cuda()\n",
        "      label = label.cuda()\n",
        "      \n",
        "    pred_label = model(image)\n",
        "    loss = criterion(pred_label, label)\n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  avg_loss = sum(losses)/len(losses)\n",
        "  return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdBW6_9MEZxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(model, test_loader):\n",
        "  model.eval()\n",
        "  device = next(model.parameters()).device.index\n",
        "  \n",
        "  total_cnt = 0\n",
        "  correct_cnt = 0\n",
        "  \n",
        "  for i, (image, label) in enumerate(test_loader):\n",
        "    if use_cuda:\n",
        "      image = image.cuda()\n",
        "      label = label.cuda()\n",
        "      \n",
        "      out = model(image)\n",
        "      _, pred_label = torch.max(out.data, 1)\n",
        "      total_cnt += image.data.size()[0]\n",
        "      correct_cnt += (pred_label == label.data).sum().item()\n",
        "      \n",
        "    return correct_cnt / total_cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PakN345jFEzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleMLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(3*32*32, 8*28*28) \n",
        "    self.act1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(8*28*28, 8*24*24)\n",
        "    self.act2 = nn.ReLU()    \n",
        "    self.fc3 = nn.Linear(8*24*24, 16*8*8)\n",
        "    self.act3 = nn.ReLU()\n",
        "    self.fc4 = nn.Linear(16*8*8, 16*4*4)\n",
        "    self.act4 = nn.ReLU()\n",
        "    \n",
        "    # Output layer\n",
        "    self.out = nn.Linear(16*4*4, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 3*32*32)\n",
        "    x = self.act1(self.fc1(x))\n",
        "    x = self.act2(self.fc2(x))\n",
        "    x = self.act3(self.fc3(x))\n",
        "    x = self.act4(self.fc4(x))\n",
        "    \n",
        "    out = self.out(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR6vmLS0AVas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleMLP_Sigmoid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleMLP_Sigmoid, self).__init__()\n",
        "    self.fc1 = nn.Linear(3*32*32, 8*28*28) \n",
        "    self.act1 = nn.Sigmoid()\n",
        "    self.fc2 = nn.Linear(8*28*28, 8*24*24)\n",
        "    self.act2 = nn.Sigmoid()    \n",
        "    self.fc3 = nn.Linear(8*24*24, 16*8*8)\n",
        "    self.act3 = nn.Sigmoid()\n",
        "    self.fc4 = nn.Linear(16*8*8, 16*4*4)\n",
        "    self.act4 = nn.Sigmoid()\n",
        "    \n",
        "    # Output layer\n",
        "    self.out = nn.Linear(16*4*4, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 3*32*32)\n",
        "    x = self.act1(self.fc1(x))\n",
        "    x = self.act2(self.fc2(x))\n",
        "    x = self.act3(self.fc3(x))\n",
        "    x = self.act4(self.fc4(x))\n",
        "    \n",
        "    out = self.out(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoOPTRRSeRsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "    # Convolution layer\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    self.conv2 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "    self.act3 = nn.ReLU()\n",
        "    \n",
        "    self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "    self.act4 = nn.ReLU()\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # Fully-Connected layer\n",
        "    self.fc1 = nn.Linear(256 * 2 * 2, 1000)\n",
        "    self.act5 = nn.ReLU()\n",
        "    self.output = nn.Linear(1000, 10)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.act1(self.conv1(x)))\n",
        "    x = self.pool2(self.act2(self.conv2(x)))\n",
        "    x = self.act3(self.conv3(x))\n",
        "    x = self.act4(self.conv4(x))\n",
        "    x = self.pool3(x)\n",
        "    \n",
        "    x = x.view(-1, 256 * 2 * 2)\n",
        "    \n",
        "    x = self.act5(self.fc1(x))\n",
        "    out = self.output(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF6QZg9oP-VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleVGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleVGG, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    \n",
        "    self.conv2 = nn.Conv2d(64, 128, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act3_1 = nn.ReLU()\n",
        "    self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act3_2 = nn.ReLU()\n",
        "    self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act3_3 = nn.ReLU()\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act4_1 = nn.ReLU()\n",
        "    self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act4_2 = nn.ReLU()\n",
        "    self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act4_3 = nn.ReLU()\n",
        "    self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    # Output layer\n",
        "    self.fc1 = nn.Linear(512 * 2 * 2, 512)\n",
        "    self.act5 = nn.ReLU()\n",
        "    self.out = nn.Linear(512, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x1 = x\n",
        "    x2 = self.act1(self.conv1(x1))\n",
        "    x3 = self.pool1(x2)\n",
        "    \n",
        "    x4 = self.act2(self.conv2(x3))\n",
        "    x5 = self.pool2(x4)\n",
        "    \n",
        "    x6 = self.act3_1(self.conv3_1(x5))\n",
        "    x7 = self.act3_2(self.conv3_2(x6))\n",
        "    x8 = self.act3_3(self.conv3_3(x7))\n",
        "    x9 = self.pool3(x8)\n",
        "    \n",
        "    x10 = self.act4_1(self.conv4_1(x9))\n",
        "    x11 = self.act4_2(self.conv4_2(x10))\n",
        "    x12 = self.act4_3(self.conv4_3(x11))\n",
        "    x13 = self.pool4(x12)\n",
        "    \n",
        "    x14 = x13.view(-1, 512 * 2 * 2)\n",
        "    \n",
        "    x15 = self.act5(self.fc1(x14))\n",
        "    \n",
        "    out = self.out(x15)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJsAENPIbUsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleResNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleResNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    \n",
        "    self.conv2 = nn.Conv2d(64, 128, kernel_size=(3,3),padding=(1,1))\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act3_1 = nn.ReLU()\n",
        "    self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act3_2 = nn.ReLU()\n",
        "    self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act3_3 = nn.ReLU()\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act4_1 = nn.ReLU()\n",
        "    self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act4_2 = nn.ReLU()\n",
        "    self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "    self.act4_3 = nn.ReLU()\n",
        "    self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    # Output layer\n",
        "    self.fc1 = nn.Linear(512 * 2 * 2, 512)\n",
        "    self.act5 = nn.ReLU()\n",
        "    self.out = nn.Linear(512, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x1 = x\n",
        "    x2 = self.act1(self.conv1(x1))\n",
        "    x3 = self.pool1(x2)\n",
        "    \n",
        "    x4 = self.act2(self.conv2(x3))\n",
        "    x5 = self.pool2(x4)\n",
        "    \n",
        "    x6 = self.act3_1(self.conv3_1(x5))\n",
        "    x7 = self.act3_2(self.conv3_2(x6))\n",
        "    x8 = self.act3_3(self.conv3_3(x7) + x6)\n",
        "    x9 = self.pool3(x8)\n",
        "    \n",
        "    x10 = self.act4_1(self.conv4_1(x9))\n",
        "    x11 = self.act4_1(self.conv4_2(x10))\n",
        "    x12 = self.act4_1(self.conv4_3(x11) + x10)\n",
        "    x13 = self.pool4(x12)\n",
        "    \n",
        "    x14 = x13.view(-1, 512 * 2 * 2)\n",
        "    \n",
        "    x15 = self.act5(self.fc1(x14))\n",
        "    \n",
        "    out = self.out(x15)\n",
        "    return out           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG6kXqCNGylt",
        "colab_type": "code",
        "outputId": "a75c8dce-68bc-49f2-bb5d-af7bc52f0533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mlp_model = SimpleMLP().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "  train_loss = train(mlp_model, train_loader)\n",
        "  train_loss_lst.append(train_loss)\n",
        "  test_accuracy = eval(mlp_model, test_loader)\n",
        "  test_accuracy_lst.append(test_accuracy)\n",
        "  \n",
        "  print(epoch+1, \"loss :\", train_loss)\n",
        "  print(\"Accuracy :\", test_accuracy)\n",
        "  \n",
        "summary(mlp_model, input_size = (3, 32, 32))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loss : 2.28015456199646\n",
            "Accuracy : 0.5\n",
            "2 loss : 2.229531097412109\n",
            "Accuracy : 0.5\n",
            "3 loss : 2.1809930324554445\n",
            "Accuracy : 0.5\n",
            "4 loss : 2.128932809829712\n",
            "Accuracy : 0.5\n",
            "5 loss : 2.0688305377960203\n",
            "Accuracy : 0.5\n",
            "6 loss : 1.9958940267562866\n",
            "Accuracy : 0.5\n",
            "7 loss : 1.900928831100464\n",
            "Accuracy : 0.5\n",
            "8 loss : 1.7741100549697877\n",
            "Accuracy : 0.5\n",
            "9 loss : 1.600469183921814\n",
            "Accuracy : 0.5\n",
            "10 loss : 1.3800851345062255\n",
            "Accuracy : 0.5\n",
            "11 loss : 1.1585801839828491\n",
            "Accuracy : 0.5\n",
            "12 loss : 0.9778548836708069\n",
            "Accuracy : 0.5\n",
            "13 loss : 0.8624639749526978\n",
            "Accuracy : 0.7\n",
            "14 loss : 0.7890028476715087\n",
            "Accuracy : 0.5\n",
            "15 loss : 0.7449694752693177\n",
            "Accuracy : 0.55\n",
            "16 loss : 0.7118423581123352\n",
            "Accuracy : 0.6\n",
            "17 loss : 0.6924200892448426\n",
            "Accuracy : 0.7\n",
            "18 loss : 0.6970789194107055\n",
            "Accuracy : 0.4\n",
            "19 loss : 0.6569279313087464\n",
            "Accuracy : 0.5\n",
            "20 loss : 0.6405163645744324\n",
            "Accuracy : 0.8\n",
            "21 loss : 0.6604423761367798\n",
            "Accuracy : 0.65\n",
            "22 loss : 0.6222152709960938\n",
            "Accuracy : 0.5\n",
            "23 loss : 0.6170679569244385\n",
            "Accuracy : 0.6\n",
            "24 loss : 0.5773829936981201\n",
            "Accuracy : 0.8\n",
            "25 loss : 0.5763012290000915\n",
            "Accuracy : 0.65\n",
            "26 loss : 0.5564316570758819\n",
            "Accuracy : 0.6\n",
            "27 loss : 0.5151184916496276\n",
            "Accuracy : 0.8\n",
            "28 loss : 0.5029158234596253\n",
            "Accuracy : 0.6\n",
            "29 loss : 0.4892833292484283\n",
            "Accuracy : 0.6\n",
            "30 loss : 0.46810752153396606\n",
            "Accuracy : 0.6\n",
            "31 loss : 0.4321440279483795\n",
            "Accuracy : 0.65\n",
            "32 loss : 0.43370933532714845\n",
            "Accuracy : 0.6\n",
            "33 loss : 0.39706515669822695\n",
            "Accuracy : 0.65\n",
            "34 loss : 0.3751396417617798\n",
            "Accuracy : 0.8\n",
            "35 loss : 0.38790165781974795\n",
            "Accuracy : 0.7\n",
            "36 loss : 0.3449352622032166\n",
            "Accuracy : 0.8\n",
            "37 loss : 0.3401439905166626\n",
            "Accuracy : 0.75\n",
            "38 loss : 0.3508468747138977\n",
            "Accuracy : 0.8\n",
            "39 loss : 0.2943221926689148\n",
            "Accuracy : 0.75\n",
            "40 loss : 0.2871906071901321\n",
            "Accuracy : 0.65\n",
            "41 loss : 0.26045334339141846\n",
            "Accuracy : 0.7\n",
            "42 loss : 0.24612934291362762\n",
            "Accuracy : 0.7\n",
            "43 loss : 0.25091938972473143\n",
            "Accuracy : 0.75\n",
            "44 loss : 0.21512357592582704\n",
            "Accuracy : 0.75\n",
            "45 loss : 0.213431978225708\n",
            "Accuracy : 0.65\n",
            "46 loss : 0.22273896336555482\n",
            "Accuracy : 0.75\n",
            "47 loss : 0.18156641721725464\n",
            "Accuracy : 0.75\n",
            "48 loss : 0.2187248572707176\n",
            "Accuracy : 0.75\n",
            "49 loss : 0.1678912192583084\n",
            "Accuracy : 0.75\n",
            "50 loss : 0.15763746201992035\n",
            "Accuracy : 0.8\n",
            "51 loss : 0.1598497673869133\n",
            "Accuracy : 0.75\n",
            "52 loss : 0.17268762439489366\n",
            "Accuracy : 0.8\n",
            "53 loss : 0.14998847246170044\n",
            "Accuracy : 0.8\n",
            "54 loss : 0.1250786930322647\n",
            "Accuracy : 0.7\n",
            "55 loss : 0.1569475695490837\n",
            "Accuracy : 0.8\n",
            "56 loss : 0.13548236340284348\n",
            "Accuracy : 0.75\n",
            "57 loss : 0.12704880833625792\n",
            "Accuracy : 0.75\n",
            "58 loss : 0.10692932307720185\n",
            "Accuracy : 0.75\n",
            "59 loss : 0.09992573857307434\n",
            "Accuracy : 0.8\n",
            "60 loss : 0.09310836046934128\n",
            "Accuracy : 0.8\n",
            "61 loss : 0.10197474807500839\n",
            "Accuracy : 0.75\n",
            "62 loss : 0.0849046215415001\n",
            "Accuracy : 0.8\n",
            "63 loss : 0.07296833023428917\n",
            "Accuracy : 0.7\n",
            "64 loss : 0.07374444529414177\n",
            "Accuracy : 0.8\n",
            "65 loss : 0.07187219187617302\n",
            "Accuracy : 0.8\n",
            "66 loss : 0.07532173991203309\n",
            "Accuracy : 0.8\n",
            "67 loss : 0.08633515387773513\n",
            "Accuracy : 0.85\n",
            "68 loss : 0.05926866829395294\n",
            "Accuracy : 0.8\n",
            "69 loss : 0.057490553706884384\n",
            "Accuracy : 0.8\n",
            "70 loss : 0.05486676692962646\n",
            "Accuracy : 0.8\n",
            "71 loss : 0.04629661999642849\n",
            "Accuracy : 0.8\n",
            "72 loss : 0.05012436397373676\n",
            "Accuracy : 0.85\n",
            "73 loss : 0.05182570442557335\n",
            "Accuracy : 0.85\n",
            "74 loss : 0.04650198072195053\n",
            "Accuracy : 0.85\n",
            "75 loss : 0.04417857564985752\n",
            "Accuracy : 0.85\n",
            "76 loss : 0.03512065447866917\n",
            "Accuracy : 0.8\n",
            "77 loss : 0.03779828138649464\n",
            "Accuracy : 0.8\n",
            "78 loss : 0.03072898406535387\n",
            "Accuracy : 0.85\n",
            "79 loss : 0.03149510845541954\n",
            "Accuracy : 0.8\n",
            "80 loss : 0.02898750752210617\n",
            "Accuracy : 0.8\n",
            "81 loss : 0.03004794605076313\n",
            "Accuracy : 0.85\n",
            "82 loss : 0.02750527374446392\n",
            "Accuracy : 0.8\n",
            "83 loss : 0.02811052817851305\n",
            "Accuracy : 0.85\n",
            "84 loss : 0.027533621340990067\n",
            "Accuracy : 0.8\n",
            "85 loss : 0.027358555421233176\n",
            "Accuracy : 0.85\n",
            "86 loss : 0.021238594129681588\n",
            "Accuracy : 0.8\n",
            "87 loss : 0.02062885742634535\n",
            "Accuracy : 0.8\n",
            "88 loss : 0.019791927374899387\n",
            "Accuracy : 0.8\n",
            "89 loss : 0.02053999900817871\n",
            "Accuracy : 0.8\n",
            "90 loss : 0.019400596618652344\n",
            "Accuracy : 0.8\n",
            "91 loss : 0.016379022598266603\n",
            "Accuracy : 0.8\n",
            "92 loss : 0.016731558181345463\n",
            "Accuracy : 0.8\n",
            "93 loss : 0.017528376914560793\n",
            "Accuracy : 0.8\n",
            "94 loss : 0.014671816863119603\n",
            "Accuracy : 0.8\n",
            "95 loss : 0.014794445130974054\n",
            "Accuracy : 0.8\n",
            "96 loss : 0.01392561886459589\n",
            "Accuracy : 0.8\n",
            "97 loss : 0.01342178825289011\n",
            "Accuracy : 0.8\n",
            "98 loss : 0.013099909014999866\n",
            "Accuracy : 0.8\n",
            "99 loss : 0.012586855981498956\n",
            "Accuracy : 0.8\n",
            "100 loss : 0.012735552899539471\n",
            "Accuracy : 0.8\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 6272]      19,273,856\n",
            "              ReLU-2                 [-1, 6272]               0\n",
            "            Linear-3                 [-1, 4608]      28,905,984\n",
            "              ReLU-4                 [-1, 4608]               0\n",
            "            Linear-5                 [-1, 1024]       4,719,616\n",
            "              ReLU-6                 [-1, 1024]               0\n",
            "            Linear-7                  [-1, 256]         262,400\n",
            "              ReLU-8                  [-1, 256]               0\n",
            "            Linear-9                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 53,164,426\n",
            "Trainable params: 53,164,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 202.81\n",
            "Estimated Total Size (MB): 203.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c1Q5FR9Axxe",
        "colab_type": "code",
        "outputId": "fc978aea-6773-429c-de9d-e9ecd6f8d515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mlp_model2 = SimpleMLP_Sigmoid().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "  train_loss = train(mlp_model, train_loader)\n",
        "  train_loss_lst.append(train_loss)\n",
        "  test_accuracy = eval(mlp_model, test_loader)\n",
        "  test_accuracy_lst.append(test_accuracy)\n",
        "  \n",
        "  print(epoch+1, \"loss :\", train_loss)\n",
        "  print(\"Accuracy :\", test_accuracy)\n",
        "  \n",
        "summary(mlp_model2, input_size = (3, 32, 32))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loss : 0.011597018409520387\n",
            "Accuracy : 0.8\n",
            "2 loss : 0.011286735534667969\n",
            "Accuracy : 0.8\n",
            "3 loss : 0.011541843600571155\n",
            "Accuracy : 0.8\n",
            "4 loss : 0.010806656070053577\n",
            "Accuracy : 0.8\n",
            "5 loss : 0.01031023021787405\n",
            "Accuracy : 0.8\n",
            "6 loss : 0.009770236164331435\n",
            "Accuracy : 0.8\n",
            "7 loss : 0.009912171214818955\n",
            "Accuracy : 0.8\n",
            "8 loss : 0.009347825031727552\n",
            "Accuracy : 0.8\n",
            "9 loss : 0.009188704565167427\n",
            "Accuracy : 0.8\n",
            "10 loss : 0.008737277984619141\n",
            "Accuracy : 0.8\n",
            "11 loss : 0.008673772867769002\n",
            "Accuracy : 0.8\n",
            "12 loss : 0.00842550741508603\n",
            "Accuracy : 0.8\n",
            "13 loss : 0.008053269516676665\n",
            "Accuracy : 0.8\n",
            "14 loss : 0.007808590028434992\n",
            "Accuracy : 0.8\n",
            "15 loss : 0.007631077663972974\n",
            "Accuracy : 0.8\n",
            "16 loss : 0.007739477045834065\n",
            "Accuracy : 0.8\n",
            "17 loss : 0.007466812245547771\n",
            "Accuracy : 0.8\n",
            "18 loss : 0.007018232252448797\n",
            "Accuracy : 0.8\n",
            "19 loss : 0.007039752043783665\n",
            "Accuracy : 0.8\n",
            "20 loss : 0.006739058624953031\n",
            "Accuracy : 0.8\n",
            "21 loss : 0.006733107566833496\n",
            "Accuracy : 0.8\n",
            "22 loss : 0.006381220929324627\n",
            "Accuracy : 0.8\n",
            "23 loss : 0.006252636946737766\n",
            "Accuracy : 0.8\n",
            "24 loss : 0.006281356886029243\n",
            "Accuracy : 0.8\n",
            "25 loss : 0.005934047815389931\n",
            "Accuracy : 0.8\n",
            "26 loss : 0.00601785653270781\n",
            "Accuracy : 0.8\n",
            "27 loss : 0.005747480364516377\n",
            "Accuracy : 0.8\n",
            "28 loss : 0.005708217620849609\n",
            "Accuracy : 0.8\n",
            "29 loss : 0.0055605650413781404\n",
            "Accuracy : 0.8\n",
            "30 loss : 0.005433812085539102\n",
            "Accuracy : 0.8\n",
            "31 loss : 0.0052647637901827695\n",
            "Accuracy : 0.8\n",
            "32 loss : 0.005327143706381321\n",
            "Accuracy : 0.8\n",
            "33 loss : 0.005070910509675741\n",
            "Accuracy : 0.8\n",
            "34 loss : 0.004941811505705118\n",
            "Accuracy : 0.8\n",
            "35 loss : 0.004891557665541768\n",
            "Accuracy : 0.8\n",
            "36 loss : 0.004769058292731642\n",
            "Accuracy : 0.8\n",
            "37 loss : 0.004644479742273689\n",
            "Accuracy : 0.8\n",
            "38 loss : 0.004621195839717984\n",
            "Accuracy : 0.8\n",
            "39 loss : 0.00447657578624785\n",
            "Accuracy : 0.8\n",
            "40 loss : 0.004430718440562487\n",
            "Accuracy : 0.8\n",
            "41 loss : 0.004392566671594977\n",
            "Accuracy : 0.8\n",
            "42 loss : 0.004338488634675741\n",
            "Accuracy : 0.8\n",
            "43 loss : 0.004227557219564915\n",
            "Accuracy : 0.8\n",
            "44 loss : 0.004180688876658678\n",
            "Accuracy : 0.8\n",
            "45 loss : 0.004108066530898213\n",
            "Accuracy : 0.8\n",
            "46 loss : 0.004044532729312778\n",
            "Accuracy : 0.8\n",
            "47 loss : 0.0039278794080019\n",
            "Accuracy : 0.8\n",
            "48 loss : 0.003944725962355733\n",
            "Accuracy : 0.8\n",
            "49 loss : 0.0038397789001464845\n",
            "Accuracy : 0.8\n",
            "50 loss : 0.003768939943984151\n",
            "Accuracy : 0.8\n",
            "51 loss : 0.0037002610974013806\n",
            "Accuracy : 0.8\n",
            "52 loss : 0.003668561019003391\n",
            "Accuracy : 0.8\n",
            "53 loss : 0.0035663271322846414\n",
            "Accuracy : 0.8\n",
            "54 loss : 0.003551225643604994\n",
            "Accuracy : 0.8\n",
            "55 loss : 0.003433089260943234\n",
            "Accuracy : 0.8\n",
            "56 loss : 0.003477039327844977\n",
            "Accuracy : 0.8\n",
            "57 loss : 0.003364767972379923\n",
            "Accuracy : 0.8\n",
            "58 loss : 0.003278460563160479\n",
            "Accuracy : 0.8\n",
            "59 loss : 0.0032366943545639516\n",
            "Accuracy : 0.8\n",
            "60 loss : 0.003198418696410954\n",
            "Accuracy : 0.8\n",
            "61 loss : 0.0032109880121424794\n",
            "Accuracy : 0.8\n",
            "62 loss : 0.003152365610003471\n",
            "Accuracy : 0.8\n",
            "63 loss : 0.0030684709548950196\n",
            "Accuracy : 0.8\n",
            "64 loss : 0.003059649420902133\n",
            "Accuracy : 0.8\n",
            "65 loss : 0.002983069373294711\n",
            "Accuracy : 0.8\n",
            "66 loss : 0.002992062596604228\n",
            "Accuracy : 0.8\n",
            "67 loss : 0.0029221868608146906\n",
            "Accuracy : 0.8\n",
            "68 loss : 0.0028614806942641735\n",
            "Accuracy : 0.8\n",
            "69 loss : 0.0028464650735259057\n",
            "Accuracy : 0.8\n",
            "70 loss : 0.002787656802684069\n",
            "Accuracy : 0.8\n",
            "71 loss : 0.00274198055267334\n",
            "Accuracy : 0.8\n",
            "72 loss : 0.0027316952124238013\n",
            "Accuracy : 0.8\n",
            "73 loss : 0.002685217862017453\n",
            "Accuracy : 0.8\n",
            "74 loss : 0.0027026319643482567\n",
            "Accuracy : 0.8\n",
            "75 loss : 0.0026217794278636576\n",
            "Accuracy : 0.8\n",
            "76 loss : 0.0026230573887005447\n",
            "Accuracy : 0.8\n",
            "77 loss : 0.0025485801976174115\n",
            "Accuracy : 0.8\n",
            "78 loss : 0.0025268840603530408\n",
            "Accuracy : 0.8\n",
            "79 loss : 0.0024812364485114814\n",
            "Accuracy : 0.8\n",
            "80 loss : 0.0024594688322395085\n",
            "Accuracy : 0.8\n",
            "81 loss : 0.0024317360483109953\n",
            "Accuracy : 0.8\n",
            "82 loss : 0.002445216150954366\n",
            "Accuracy : 0.8\n",
            "83 loss : 0.0024123955052345993\n",
            "Accuracy : 0.8\n",
            "84 loss : 0.002375335735268891\n",
            "Accuracy : 0.8\n",
            "85 loss : 0.002315211296081543\n",
            "Accuracy : 0.8\n",
            "86 loss : 0.002297816262580454\n",
            "Accuracy : 0.8\n",
            "87 loss : 0.002252488140948117\n",
            "Accuracy : 0.8\n",
            "88 loss : 0.002253303537145257\n",
            "Accuracy : 0.8\n",
            "89 loss : 0.002220702148042619\n",
            "Accuracy : 0.8\n",
            "90 loss : 0.002192602143622935\n",
            "Accuracy : 0.8\n",
            "91 loss : 0.0021713876631110907\n",
            "Accuracy : 0.8\n",
            "92 loss : 0.0021563244052231314\n",
            "Accuracy : 0.8\n",
            "93 loss : 0.0021516275592148304\n",
            "Accuracy : 0.8\n",
            "94 loss : 0.0021061515901237724\n",
            "Accuracy : 0.8\n",
            "95 loss : 0.002076086984016001\n",
            "Accuracy : 0.8\n",
            "96 loss : 0.002062797569669783\n",
            "Accuracy : 0.8\n",
            "97 loss : 0.00205230712890625\n",
            "Accuracy : 0.8\n",
            "98 loss : 0.0020404052920639515\n",
            "Accuracy : 0.8\n",
            "99 loss : 0.0019878005841746926\n",
            "Accuracy : 0.8\n",
            "100 loss : 0.0019841003231704235\n",
            "Accuracy : 0.8\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 6272]      19,273,856\n",
            "           Sigmoid-2                 [-1, 6272]               0\n",
            "            Linear-3                 [-1, 4608]      28,905,984\n",
            "           Sigmoid-4                 [-1, 4608]               0\n",
            "            Linear-5                 [-1, 1024]       4,719,616\n",
            "           Sigmoid-6                 [-1, 1024]               0\n",
            "            Linear-7                  [-1, 256]         262,400\n",
            "           Sigmoid-8                  [-1, 256]               0\n",
            "            Linear-9                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 53,164,426\n",
            "Trainable params: 53,164,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 202.81\n",
            "Estimated Total Size (MB): 203.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPA5S6PHkwZd",
        "colab_type": "code",
        "outputId": "77224a94-5d80-4ac0-9c64-f4f5933e0cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cnn_model = SimpleCNN().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "  train_loss = train(cnn_model, train_loader)\n",
        "  train_loss_lst.append(train_loss)\n",
        "  test_accuracy = eval(cnn_model, test_loader)\n",
        "  test_accuracy_lst.append(test_accuracy)\n",
        "  \n",
        "  print(epoch+1, \"loss :\", train_loss)\n",
        "  print(\"Accuracy :\", test_accuracy)\n",
        "  \n",
        "summary(cnn_model, input_size = (3,32,32))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loss : 2.2888842582702638\n",
            "Accuracy : 0.5\n",
            "2 loss : 2.2410012245178224\n",
            "Accuracy : 0.5\n",
            "3 loss : 2.1907605648040773\n",
            "Accuracy : 0.5\n",
            "4 loss : 2.1325640201568605\n",
            "Accuracy : 0.5\n",
            "5 loss : 2.0566579818725588\n",
            "Accuracy : 0.5\n",
            "6 loss : 1.9420445919036866\n",
            "Accuracy : 0.55\n",
            "7 loss : 1.7396649837493896\n",
            "Accuracy : 0.4\n",
            "8 loss : 1.360076117515564\n",
            "Accuracy : 0.5\n",
            "9 loss : 0.9619580626487731\n",
            "Accuracy : 0.5\n",
            "10 loss : 0.7870545029640198\n",
            "Accuracy : 0.5\n",
            "11 loss : 0.7320159196853637\n",
            "Accuracy : 0.5\n",
            "12 loss : 0.7154817700386047\n",
            "Accuracy : 0.5\n",
            "13 loss : 0.713418447971344\n",
            "Accuracy : 0.5\n",
            "14 loss : 0.7434101939201355\n",
            "Accuracy : 0.5\n",
            "15 loss : 0.6996376156806946\n",
            "Accuracy : 0.5\n",
            "16 loss : 0.7255079627037049\n",
            "Accuracy : 0.5\n",
            "17 loss : 0.725289237499237\n",
            "Accuracy : 0.5\n",
            "18 loss : 0.7065657258033753\n",
            "Accuracy : 0.5\n",
            "19 loss : 0.7306170582771301\n",
            "Accuracy : 0.5\n",
            "20 loss : 0.7035523295402527\n",
            "Accuracy : 0.5\n",
            "21 loss : 0.6955435752868653\n",
            "Accuracy : 0.5\n",
            "22 loss : 0.706280529499054\n",
            "Accuracy : 0.5\n",
            "23 loss : 0.7011498808860779\n",
            "Accuracy : 0.5\n",
            "24 loss : 0.7280344843864441\n",
            "Accuracy : 0.5\n",
            "25 loss : 0.7009428381919861\n",
            "Accuracy : 0.5\n",
            "26 loss : 0.7697296738624573\n",
            "Accuracy : 0.65\n",
            "27 loss : 0.7075074076652527\n",
            "Accuracy : 0.5\n",
            "28 loss : 0.7424176573753357\n",
            "Accuracy : 0.5\n",
            "29 loss : 0.6957627177238465\n",
            "Accuracy : 0.5\n",
            "30 loss : 0.7091555833816529\n",
            "Accuracy : 0.6\n",
            "31 loss : 0.719593060016632\n",
            "Accuracy : 0.5\n",
            "32 loss : 0.7430429458618164\n",
            "Accuracy : 0.5\n",
            "33 loss : 0.7012824416160583\n",
            "Accuracy : 0.5\n",
            "34 loss : 0.724078917503357\n",
            "Accuracy : 0.5\n",
            "35 loss : 0.7151583313941956\n",
            "Accuracy : 0.5\n",
            "36 loss : 0.7213825345039367\n",
            "Accuracy : 0.5\n",
            "37 loss : 0.7123473644256592\n",
            "Accuracy : 0.5\n",
            "38 loss : 0.7057098746299744\n",
            "Accuracy : 0.5\n",
            "39 loss : 0.6890898942947388\n",
            "Accuracy : 0.5\n",
            "40 loss : 0.6766377210617065\n",
            "Accuracy : 0.5\n",
            "41 loss : 0.6685057997703552\n",
            "Accuracy : 0.5\n",
            "42 loss : 0.6676640272140503\n",
            "Accuracy : 0.5\n",
            "43 loss : 0.6860596060752868\n",
            "Accuracy : 0.5\n",
            "44 loss : 0.671319580078125\n",
            "Accuracy : 0.5\n",
            "45 loss : 0.6797066569328308\n",
            "Accuracy : 0.55\n",
            "46 loss : 0.6580255270004273\n",
            "Accuracy : 0.65\n",
            "47 loss : 0.6549269080162048\n",
            "Accuracy : 0.5\n",
            "48 loss : 0.6600854277610779\n",
            "Accuracy : 0.6\n",
            "49 loss : 0.6554799199104309\n",
            "Accuracy : 0.5\n",
            "50 loss : 0.680073869228363\n",
            "Accuracy : 0.5\n",
            "51 loss : 0.6550630569458008\n",
            "Accuracy : 0.5\n",
            "52 loss : 0.7079726219177246\n",
            "Accuracy : 0.75\n",
            "53 loss : 0.7126689910888672\n",
            "Accuracy : 0.6\n",
            "54 loss : 0.643570852279663\n",
            "Accuracy : 0.65\n",
            "55 loss : 0.6463322043418884\n",
            "Accuracy : 0.5\n",
            "56 loss : 0.6345109581947327\n",
            "Accuracy : 0.8\n",
            "57 loss : 0.668855094909668\n",
            "Accuracy : 0.5\n",
            "58 loss : 0.6222523093223572\n",
            "Accuracy : 0.55\n",
            "59 loss : 0.6464769005775451\n",
            "Accuracy : 0.5\n",
            "60 loss : 0.6613417744636536\n",
            "Accuracy : 0.5\n",
            "61 loss : 0.6218239188194274\n",
            "Accuracy : 0.65\n",
            "62 loss : 0.5960719347000122\n",
            "Accuracy : 0.5\n",
            "63 loss : 0.5923609256744384\n",
            "Accuracy : 0.8\n",
            "64 loss : 0.6322727203369141\n",
            "Accuracy : 0.65\n",
            "65 loss : 0.6107812881469726\n",
            "Accuracy : 0.65\n",
            "66 loss : 0.5686328768730163\n",
            "Accuracy : 0.5\n",
            "67 loss : 0.5529830694198609\n",
            "Accuracy : 0.55\n",
            "68 loss : 0.5467986166477203\n",
            "Accuracy : 0.5\n",
            "69 loss : 0.5349848926067352\n",
            "Accuracy : 0.7\n",
            "70 loss : 0.5862103879451752\n",
            "Accuracy : 0.75\n",
            "71 loss : 0.5102077186107635\n",
            "Accuracy : 0.65\n",
            "72 loss : 0.5805990695953369\n",
            "Accuracy : 0.8\n",
            "73 loss : 0.5358346819877624\n",
            "Accuracy : 0.75\n",
            "74 loss : 0.5350949227809906\n",
            "Accuracy : 0.75\n",
            "75 loss : 0.5021365642547607\n",
            "Accuracy : 0.55\n",
            "76 loss : 0.46052390336990356\n",
            "Accuracy : 0.65\n",
            "77 loss : 0.5365514397621155\n",
            "Accuracy : 0.6\n",
            "78 loss : 0.45290812849998474\n",
            "Accuracy : 0.55\n",
            "79 loss : 0.45848387479782104\n",
            "Accuracy : 0.55\n",
            "80 loss : 0.4325567364692688\n",
            "Accuracy : 0.6\n",
            "81 loss : 0.42409666180610656\n",
            "Accuracy : 0.6\n",
            "82 loss : 0.4978547036647797\n",
            "Accuracy : 0.75\n",
            "83 loss : 0.4140189290046692\n",
            "Accuracy : 0.55\n",
            "84 loss : 0.49638243317604064\n",
            "Accuracy : 0.5\n",
            "85 loss : 0.6980438351631164\n",
            "Accuracy : 0.75\n",
            "86 loss : 0.4365461230278015\n",
            "Accuracy : 0.6\n",
            "87 loss : 0.42623149156570433\n",
            "Accuracy : 0.6\n",
            "88 loss : 0.4059056341648102\n",
            "Accuracy : 0.6\n",
            "89 loss : 0.46356449127197263\n",
            "Accuracy : 0.75\n",
            "90 loss : 0.4626211166381836\n",
            "Accuracy : 0.6\n",
            "91 loss : 0.4025581181049347\n",
            "Accuracy : 0.6\n",
            "92 loss : 0.3749165296554565\n",
            "Accuracy : 0.6\n",
            "93 loss : 0.4846708655357361\n",
            "Accuracy : 0.75\n",
            "94 loss : 0.47013491988182066\n",
            "Accuracy : 0.65\n",
            "95 loss : 0.37190435230731966\n",
            "Accuracy : 0.5\n",
            "96 loss : 0.41434015333652496\n",
            "Accuracy : 0.6\n",
            "97 loss : 0.38318878412246704\n",
            "Accuracy : 0.6\n",
            "98 loss : 0.359407377243042\n",
            "Accuracy : 0.6\n",
            "99 loss : 0.3913250267505646\n",
            "Accuracy : 0.65\n",
            "100 loss : 0.4878831088542938\n",
            "Accuracy : 0.65\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           1,792\n",
            "              ReLU-2           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-3             [-1, 64, 8, 8]               0\n",
            "            Conv2d-4            [-1, 192, 8, 8]         110,784\n",
            "              ReLU-5            [-1, 192, 8, 8]               0\n",
            "         MaxPool2d-6            [-1, 192, 4, 4]               0\n",
            "            Conv2d-7            [-1, 384, 4, 4]         663,936\n",
            "              ReLU-8            [-1, 384, 4, 4]               0\n",
            "            Conv2d-9            [-1, 256, 4, 4]         884,992\n",
            "             ReLU-10            [-1, 256, 4, 4]               0\n",
            "        MaxPool2d-11            [-1, 256, 2, 2]               0\n",
            "           Linear-12                 [-1, 1000]       1,025,000\n",
            "             ReLU-13                 [-1, 1000]               0\n",
            "           Linear-14                   [-1, 10]          10,010\n",
            "================================================================\n",
            "Total params: 2,696,514\n",
            "Trainable params: 2,696,514\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.67\n",
            "Params size (MB): 10.29\n",
            "Estimated Total Size (MB): 10.97\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qhrL3G8lBFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf5dc783-a381-4bf6-832b-33f11bd39a26"
      },
      "source": [
        "vgg_model = SimpleVGG().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "  train_loss = train(vgg_model, train_loader)\n",
        "  train_loss_lst.append(train_loss)\n",
        "  test_accuracy = eval(vgg_model, test_loader)\n",
        "  test_accuracy_lst.append(test_accuracy)\n",
        "  \n",
        "  print(epoch+1, \"loss :\", train_loss)\n",
        "  print(\"Accuracy :\", test_accuracy)\n",
        "  \n",
        "summary(vgg_model, input_size = (3,32,32))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loss : 2.2813321113586427\n",
            "Accuracy : 0.5\n",
            "2 loss : 2.2572453022003174\n",
            "Accuracy : 0.5\n",
            "3 loss : 2.233183431625366\n",
            "Accuracy : 0.5\n",
            "4 loss : 2.209451103210449\n",
            "Accuracy : 0.5\n",
            "5 loss : 2.1861791133880617\n",
            "Accuracy : 0.5\n",
            "6 loss : 2.162987470626831\n",
            "Accuracy : 0.5\n",
            "7 loss : 2.140240716934204\n",
            "Accuracy : 0.5\n",
            "8 loss : 2.117628335952759\n",
            "Accuracy : 0.5\n",
            "9 loss : 2.0953235149383547\n",
            "Accuracy : 0.5\n",
            "10 loss : 2.073278045654297\n",
            "Accuracy : 0.5\n",
            "11 loss : 2.051110315322876\n",
            "Accuracy : 0.5\n",
            "12 loss : 2.0294042110443113\n",
            "Accuracy : 0.5\n",
            "13 loss : 2.007502222061157\n",
            "Accuracy : 0.5\n",
            "14 loss : 1.9857707262039184\n",
            "Accuracy : 0.5\n",
            "15 loss : 1.9642173290252685\n",
            "Accuracy : 0.5\n",
            "16 loss : 1.9428031682968139\n",
            "Accuracy : 0.5\n",
            "17 loss : 1.9213690042495728\n",
            "Accuracy : 0.5\n",
            "18 loss : 1.899807906150818\n",
            "Accuracy : 0.5\n",
            "19 loss : 1.8783287763595582\n",
            "Accuracy : 0.5\n",
            "20 loss : 1.8566905975341796\n",
            "Accuracy : 0.5\n",
            "21 loss : 1.8351734399795532\n",
            "Accuracy : 0.5\n",
            "22 loss : 1.8136045217514039\n",
            "Accuracy : 0.5\n",
            "23 loss : 1.7919514894485473\n",
            "Accuracy : 0.5\n",
            "24 loss : 1.7703530073165894\n",
            "Accuracy : 0.5\n",
            "25 loss : 1.748553252220154\n",
            "Accuracy : 0.5\n",
            "26 loss : 1.7266020774841309\n",
            "Accuracy : 0.5\n",
            "27 loss : 1.704599142074585\n",
            "Accuracy : 0.5\n",
            "28 loss : 1.6824263334274292\n",
            "Accuracy : 0.5\n",
            "29 loss : 1.6602995157241822\n",
            "Accuracy : 0.5\n",
            "30 loss : 1.6375649452209473\n",
            "Accuracy : 0.5\n",
            "31 loss : 1.615003752708435\n",
            "Accuracy : 0.5\n",
            "32 loss : 1.591775369644165\n",
            "Accuracy : 0.5\n",
            "33 loss : 1.5688690662384033\n",
            "Accuracy : 0.5\n",
            "34 loss : 1.5451836585998535\n",
            "Accuracy : 0.5\n",
            "35 loss : 1.5211099147796632\n",
            "Accuracy : 0.5\n",
            "36 loss : 1.496975302696228\n",
            "Accuracy : 0.5\n",
            "37 loss : 1.4722936391830443\n",
            "Accuracy : 0.5\n",
            "38 loss : 1.4473264694213868\n",
            "Accuracy : 0.5\n",
            "39 loss : 1.4219263076782227\n",
            "Accuracy : 0.5\n",
            "40 loss : 1.3961901903152465\n",
            "Accuracy : 0.5\n",
            "41 loss : 1.3701255321502686\n",
            "Accuracy : 0.5\n",
            "42 loss : 1.3433723449707031\n",
            "Accuracy : 0.5\n",
            "43 loss : 1.3165917158126832\n",
            "Accuracy : 0.5\n",
            "44 loss : 1.2892202854156494\n",
            "Accuracy : 0.5\n",
            "45 loss : 1.2616301774978638\n",
            "Accuracy : 0.5\n",
            "46 loss : 1.2335038900375366\n",
            "Accuracy : 0.5\n",
            "47 loss : 1.2054903030395507\n",
            "Accuracy : 0.5\n",
            "48 loss : 1.1779924631118774\n",
            "Accuracy : 0.5\n",
            "49 loss : 1.1485617637634278\n",
            "Accuracy : 0.5\n",
            "50 loss : 1.1204442739486695\n",
            "Accuracy : 0.5\n",
            "51 loss : 1.0922649383544922\n",
            "Accuracy : 0.5\n",
            "52 loss : 1.0642558097839356\n",
            "Accuracy : 0.5\n",
            "53 loss : 1.0370323419570924\n",
            "Accuracy : 0.5\n",
            "54 loss : 1.0096288800239563\n",
            "Accuracy : 0.5\n",
            "55 loss : 0.9834575057029724\n",
            "Accuracy : 0.5\n",
            "56 loss : 0.9583967924118042\n",
            "Accuracy : 0.5\n",
            "57 loss : 0.935806405544281\n",
            "Accuracy : 0.5\n",
            "58 loss : 0.9117716431617737\n",
            "Accuracy : 0.5\n",
            "59 loss : 0.8902950525283814\n",
            "Accuracy : 0.5\n",
            "60 loss : 0.8720495343208313\n",
            "Accuracy : 0.5\n",
            "61 loss : 0.8531358242034912\n",
            "Accuracy : 0.5\n",
            "62 loss : 0.835073959827423\n",
            "Accuracy : 0.5\n",
            "63 loss : 0.8196343421936035\n",
            "Accuracy : 0.5\n",
            "64 loss : 0.807611346244812\n",
            "Accuracy : 0.5\n",
            "65 loss : 0.7932046413421631\n",
            "Accuracy : 0.5\n",
            "66 loss : 0.7823063850402832\n",
            "Accuracy : 0.5\n",
            "67 loss : 0.7736411452293396\n",
            "Accuracy : 0.5\n",
            "68 loss : 0.763530170917511\n",
            "Accuracy : 0.5\n",
            "69 loss : 0.756692397594452\n",
            "Accuracy : 0.5\n",
            "70 loss : 0.7482397675514221\n",
            "Accuracy : 0.5\n",
            "71 loss : 0.7417434811592102\n",
            "Accuracy : 0.5\n",
            "72 loss : 0.7363447785377503\n",
            "Accuracy : 0.5\n",
            "73 loss : 0.7324734449386596\n",
            "Accuracy : 0.5\n",
            "74 loss : 0.7272256493568421\n",
            "Accuracy : 0.5\n",
            "75 loss : 0.7261221170425415\n",
            "Accuracy : 0.5\n",
            "76 loss : 0.7248319029808045\n",
            "Accuracy : 0.5\n",
            "77 loss : 0.7174023032188416\n",
            "Accuracy : 0.5\n",
            "78 loss : 0.7158433556556701\n",
            "Accuracy : 0.5\n",
            "79 loss : 0.7139341592788696\n",
            "Accuracy : 0.5\n",
            "80 loss : 0.7113465189933776\n",
            "Accuracy : 0.5\n",
            "81 loss : 0.7099092245101929\n",
            "Accuracy : 0.5\n",
            "82 loss : 0.7092251896858215\n",
            "Accuracy : 0.5\n",
            "83 loss : 0.7086083889007568\n",
            "Accuracy : 0.5\n",
            "84 loss : 0.7054258704185485\n",
            "Accuracy : 0.5\n",
            "85 loss : 0.7061758279800415\n",
            "Accuracy : 0.5\n",
            "86 loss : 0.7068062543869018\n",
            "Accuracy : 0.5\n",
            "87 loss : 0.7026761054992676\n",
            "Accuracy : 0.5\n",
            "88 loss : 0.7022768259048462\n",
            "Accuracy : 0.5\n",
            "89 loss : 0.7008730292320251\n",
            "Accuracy : 0.5\n",
            "90 loss : 0.701422107219696\n",
            "Accuracy : 0.5\n",
            "91 loss : 0.7002742290496826\n",
            "Accuracy : 0.5\n",
            "92 loss : 0.6997459053993225\n",
            "Accuracy : 0.5\n",
            "93 loss : 0.7050553560256958\n",
            "Accuracy : 0.5\n",
            "94 loss : 0.7030566215515137\n",
            "Accuracy : 0.5\n",
            "95 loss : 0.7103094100952149\n",
            "Accuracy : 0.5\n",
            "96 loss : 0.6994107365608215\n",
            "Accuracy : 0.5\n",
            "97 loss : 0.7009305477142334\n",
            "Accuracy : 0.5\n",
            "98 loss : 0.698256003856659\n",
            "Accuracy : 0.5\n",
            "99 loss : 0.7003583669662475\n",
            "Accuracy : 0.5\n",
            "100 loss : 0.6988639116287232\n",
            "Accuracy : 0.5\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
            "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-5          [-1, 128, 16, 16]               0\n",
            "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
            "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
            "              ReLU-8            [-1, 256, 8, 8]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-10            [-1, 256, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-12            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-13            [-1, 256, 4, 4]               0\n",
            "           Conv2d-14            [-1, 512, 4, 4]       1,180,160\n",
            "             ReLU-15            [-1, 512, 4, 4]               0\n",
            "           Conv2d-16            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-17            [-1, 512, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-19            [-1, 512, 4, 4]               0\n",
            "        AvgPool2d-20            [-1, 512, 2, 2]               0\n",
            "           Linear-21                  [-1, 512]       1,049,088\n",
            "             ReLU-22                  [-1, 512]               0\n",
            "           Linear-23                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 8,504,970\n",
            "Trainable params: 8,504,970\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.87\n",
            "Params size (MB): 32.44\n",
            "Estimated Total Size (MB): 35.32\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMxFQVJulHlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd8e4e9a-35b3-4b68-ef31-44f8cac75596"
      },
      "source": [
        "resnet_model = SimpleResNet().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "  train_loss = train(resnet_model, train_loader)\n",
        "  train_loss_lst.append(train_loss)\n",
        "  test_accuracy = eval(resnet_model, test_loader)\n",
        "  test_accuracy_lst.append(test_accuracy)\n",
        "  \n",
        "  print(epoch+1, \"loss :\", train_loss)\n",
        "  print(\"Accuracy :\", test_accuracy)\n",
        "  \n",
        "summary(resnet_model, input_size = (3,32,32))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loss : 2.277858018875122\n",
            "Accuracy : 0.5\n",
            "2 loss : 2.2413113117218018\n",
            "Accuracy : 0.5\n",
            "3 loss : 2.204602527618408\n",
            "Accuracy : 0.5\n",
            "4 loss : 2.166339111328125\n",
            "Accuracy : 0.5\n",
            "5 loss : 2.1241406917572023\n",
            "Accuracy : 0.5\n",
            "6 loss : 2.073292541503906\n",
            "Accuracy : 0.5\n",
            "7 loss : 2.0073747634887695\n",
            "Accuracy : 0.5\n",
            "8 loss : 1.9103617668151855\n",
            "Accuracy : 0.5\n",
            "9 loss : 1.7436917304992676\n",
            "Accuracy : 0.5\n",
            "10 loss : 1.417808437347412\n",
            "Accuracy : 0.5\n",
            "11 loss : 0.9863250017166137\n",
            "Accuracy : 0.5\n",
            "12 loss : 0.780078125\n",
            "Accuracy : 0.5\n",
            "13 loss : 0.7425066828727722\n",
            "Accuracy : 0.5\n",
            "14 loss : 0.7628249049186706\n",
            "Accuracy : 0.5\n",
            "15 loss : 0.7793685555458069\n",
            "Accuracy : 0.5\n",
            "16 loss : 0.7298925161361695\n",
            "Accuracy : 0.5\n",
            "17 loss : 0.73058522939682\n",
            "Accuracy : 0.5\n",
            "18 loss : 0.7110967040061951\n",
            "Accuracy : 0.4\n",
            "19 loss : 0.7101500630378723\n",
            "Accuracy : 0.5\n",
            "20 loss : 0.7189873456954956\n",
            "Accuracy : 0.5\n",
            "21 loss : 0.7063756227493286\n",
            "Accuracy : 0.4\n",
            "22 loss : 0.7353615522384643\n",
            "Accuracy : 0.5\n",
            "23 loss : 0.7034193873405457\n",
            "Accuracy : 0.5\n",
            "24 loss : 0.6969196557998657\n",
            "Accuracy : 0.5\n",
            "25 loss : 0.7477450847625733\n",
            "Accuracy : 0.5\n",
            "26 loss : 0.7342928409576416\n",
            "Accuracy : 0.5\n",
            "27 loss : 0.735082495212555\n",
            "Accuracy : 0.5\n",
            "28 loss : 0.7098001956939697\n",
            "Accuracy : 0.5\n",
            "29 loss : 0.6988574385643005\n",
            "Accuracy : 0.5\n",
            "30 loss : 0.7021032810211182\n",
            "Accuracy : 0.5\n",
            "31 loss : 0.8051405549049377\n",
            "Accuracy : 0.5\n",
            "32 loss : 0.695287573337555\n",
            "Accuracy : 0.5\n",
            "33 loss : 0.7406438112258911\n",
            "Accuracy : 0.5\n",
            "34 loss : 0.713957154750824\n",
            "Accuracy : 0.5\n",
            "35 loss : 0.7987885117530823\n",
            "Accuracy : 0.5\n",
            "36 loss : 0.6969141006469727\n",
            "Accuracy : 0.5\n",
            "37 loss : 0.7125613331794739\n",
            "Accuracy : 0.4\n",
            "38 loss : 0.6911633491516114\n",
            "Accuracy : 0.5\n",
            "39 loss : 0.6850609302520752\n",
            "Accuracy : 0.45\n",
            "40 loss : 0.6821390151977539\n",
            "Accuracy : 0.5\n",
            "41 loss : 0.7286206603050231\n",
            "Accuracy : 0.5\n",
            "42 loss : 0.6931379437446594\n",
            "Accuracy : 0.35\n",
            "43 loss : 0.7565083146095276\n",
            "Accuracy : 0.5\n",
            "44 loss : 0.7223315119743348\n",
            "Accuracy : 0.5\n",
            "45 loss : 0.7066525101661683\n",
            "Accuracy : 0.5\n",
            "46 loss : 0.6784276485443115\n",
            "Accuracy : 0.6\n",
            "47 loss : 0.6707705378532409\n",
            "Accuracy : 0.5\n",
            "48 loss : 0.7097598671913147\n",
            "Accuracy : 0.5\n",
            "49 loss : 0.6817065119743347\n",
            "Accuracy : 0.4\n",
            "50 loss : 0.7115032076835632\n",
            "Accuracy : 0.5\n",
            "51 loss : 0.6666103601455688\n",
            "Accuracy : 0.5\n",
            "52 loss : 0.6917293548583985\n",
            "Accuracy : 0.5\n",
            "53 loss : 0.7127459406852722\n",
            "Accuracy : 0.5\n",
            "54 loss : 0.7346163392066956\n",
            "Accuracy : 0.6\n",
            "55 loss : 0.6805630445480346\n",
            "Accuracy : 0.5\n",
            "56 loss : 0.6960156202316284\n",
            "Accuracy : 0.5\n",
            "57 loss : 0.6849481701850891\n",
            "Accuracy : 0.5\n",
            "58 loss : 0.7314272522926331\n",
            "Accuracy : 0.5\n",
            "59 loss : 0.6672554254531861\n",
            "Accuracy : 0.35\n",
            "60 loss : 0.6689617872238159\n",
            "Accuracy : 0.6\n",
            "61 loss : 0.6512992739677429\n",
            "Accuracy : 0.5\n",
            "62 loss : 0.7142930865287781\n",
            "Accuracy : 0.5\n",
            "63 loss : 0.6635352373123169\n",
            "Accuracy : 0.5\n",
            "64 loss : 0.6993547558784485\n",
            "Accuracy : 0.5\n",
            "65 loss : 0.7529415249824524\n",
            "Accuracy : 0.45\n",
            "66 loss : 0.661557412147522\n",
            "Accuracy : 0.4\n",
            "67 loss : 0.6593812942504883\n",
            "Accuracy : 0.45\n",
            "68 loss : 0.7024097204208374\n",
            "Accuracy : 0.6\n",
            "69 loss : 0.6663493394851685\n",
            "Accuracy : 0.45\n",
            "70 loss : 0.6515860438346863\n",
            "Accuracy : 0.6\n",
            "71 loss : 0.6590649008750915\n",
            "Accuracy : 0.35\n",
            "72 loss : 0.6400278806686401\n",
            "Accuracy : 0.4\n",
            "73 loss : 0.6691315174102783\n",
            "Accuracy : 0.6\n",
            "74 loss : 0.70394948720932\n",
            "Accuracy : 0.55\n",
            "75 loss : 0.650786030292511\n",
            "Accuracy : 0.4\n",
            "76 loss : 0.6535981297492981\n",
            "Accuracy : 0.35\n",
            "77 loss : 0.6362642765045166\n",
            "Accuracy : 0.35\n",
            "78 loss : 0.6506541013717652\n",
            "Accuracy : 0.6\n",
            "79 loss : 0.631781256198883\n",
            "Accuracy : 0.4\n",
            "80 loss : 0.6706683397293091\n",
            "Accuracy : 0.4\n",
            "81 loss : 0.6370501756668091\n",
            "Accuracy : 0.4\n",
            "82 loss : 0.7210040092468262\n",
            "Accuracy : 0.35\n",
            "83 loss : 0.6178640484809875\n",
            "Accuracy : 0.4\n",
            "84 loss : 0.6332651376724243\n",
            "Accuracy : 0.6\n",
            "85 loss : 0.8455902457237243\n",
            "Accuracy : 0.4\n",
            "86 loss : 0.6336123943328857\n",
            "Accuracy : 0.5\n",
            "87 loss : 0.6269999146461487\n",
            "Accuracy : 0.5\n",
            "88 loss : 0.6178916811943054\n",
            "Accuracy : 0.35\n",
            "89 loss : 0.6543906569480896\n",
            "Accuracy : 0.4\n",
            "90 loss : 0.6411669015884399\n",
            "Accuracy : 0.5\n",
            "91 loss : 0.5878591418266297\n",
            "Accuracy : 0.4\n",
            "92 loss : 0.5925353407859802\n",
            "Accuracy : 0.5\n",
            "93 loss : 0.6214234709739686\n",
            "Accuracy : 0.6\n",
            "94 loss : 0.6422378420829773\n",
            "Accuracy : 0.6\n",
            "95 loss : 0.6778189659118652\n",
            "Accuracy : 0.55\n",
            "96 loss : 0.5976711988449097\n",
            "Accuracy : 0.5\n",
            "97 loss : 0.5961312532424927\n",
            "Accuracy : 0.5\n",
            "98 loss : 0.6564021050930023\n",
            "Accuracy : 0.35\n",
            "99 loss : 0.6353730201721192\n",
            "Accuracy : 0.6\n",
            "100 loss : 0.6591410756111145\n",
            "Accuracy : 0.4\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
            "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-5          [-1, 128, 16, 16]               0\n",
            "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
            "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
            "              ReLU-8            [-1, 256, 8, 8]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-10            [-1, 256, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-12            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-13            [-1, 256, 4, 4]               0\n",
            "           Conv2d-14            [-1, 512, 4, 4]       1,180,160\n",
            "             ReLU-15            [-1, 512, 4, 4]               0\n",
            "           Conv2d-16            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-17            [-1, 512, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-19            [-1, 512, 4, 4]               0\n",
            "        AvgPool2d-20            [-1, 512, 2, 2]               0\n",
            "           Linear-21                  [-1, 512]       1,049,088\n",
            "             ReLU-22                  [-1, 512]               0\n",
            "           Linear-23                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 8,504,970\n",
            "Trainable params: 8,504,970\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.87\n",
            "Params size (MB): 32.44\n",
            "Estimated Total Size (MB): 35.32\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}